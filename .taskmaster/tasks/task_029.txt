# Task ID: 29
# Title: Unify LLM adapters for interchangeable providers while preserving provider-specific capabilities (2025 parity)
# Status: done
# Dependencies: None
# Priority: high
# Description: Make all LLM providers (OpenAI, Anthropic Claude, Azure OpenAI, AWS Bedrock) interchangeable with a uniform API, consistent token budgeting, prompt sourcing, response schemas, and metadata, while preserving provider-specific capabilities like reasoning/thinking modes and model-specific limits.
# Details:
Objectives:
- Uniform `LLMPort` contract across providers; consistent return schemas and metadata
- Centralized token budgeting and prompt sourcing
- Provider-specific features preserved (Claude extended thinking, OpenAI o-series Responses API, model-specific limits)
- Router conforms 1:1 to `LLMPort`

Acceptance criteria:
- Any provider can be swapped in `LLMRouter(default_provider=...)` with no call-site changes
- All four operations (`generate_tests`, `analyze_code`, `refine_content`, `generate_test_plan`) succeed on all providers and return the same top-level structure
- Per-request token budgeting works for all providers
- Claude thinking budgets applied when supported; OpenAI o-series uses Responses API and ignores custom temperature
- Router method signatures match `LLMPort` exactly
- Parity tests pass across providers (with and without credentials/stub mode)

# Test Strategy:
- Add parameterized provider tests for all operations; verify consistent schemas and metadata
- Add budgeting tests to assert per-request max_tokens/thinking tokens computed
- Add OpenAI o-series branch test (Responses API path taken) and temperature behavior
- Add router signature and pass-through tests
- Add metadata normalization tests (model mapping for Azure/Bedrock)
- Ensure cost tracking doesn't fail operations

# Subtasks:
## 1. Standardize LLMPort Contract and Response Schema Across Providers [done]
### Dependencies: None
### Description: Define and implement a uniform LLMPort interface for all providers (OpenAI, Anthropic Claude, Azure OpenAI, AWS Bedrock), ensuring consistent method signatures, return schemas, and metadata fields. Normalize response structures and metadata to enable seamless provider interchangeability.
### Details:
Specify a canonical LLMPort contract with strict input/output types and metadata keys. Refactor all provider adapters to conform to this contract. Ensure all four core operations (`generate_tests`, `analyze_code`, `refine_content`, `generate_test_plan`) return identical top-level structures regardless of provider.

## 2. Implement Centralized Token Budgeting and Prompt Sourcing Logic [done]
### Dependencies: 29.1
### Description: Centralize token budgeting logic for prompt, output, and provider-specific tokens (e.g., Claude thinking tokens), enforcing provider-specific caps and budgeting rules. Ensure prompt sourcing is consistent and budgeting is enforced per request.
### Details:
Develop a shared budgeting module that calculates and enforces max tokens for each request, including provider-specific constraints (e.g., Claude thinking budgets, OpenAI o-series output limits). Integrate prompt sourcing so all adapters use the same prompt construction logic.

## 3. Preserve and Route Provider-Specific Capabilities and Behaviors [done]
### Dependencies: 29.1, 29.2
### Description: Implement mechanisms to expose and preserve provider-specific features (e.g., Claude extended thinking, OpenAI o-series Responses API and temperature handling, Azure/Bedrock model mapping) within the unified adapter framework.
### Details:
Add conditional logic and capability flags to adapters and router to ensure provider-specific features are accessible and correctly routed. For example, apply Claude thinking budgets only when supported, use OpenAI o-series Responses API and ignore custom temperature, and map Azure/Bedrock models appropriately.

## 4. Align Router Methods and Pass-Through with LLMPort Contract [done]
### Dependencies: 29.1, 29.2, 29.3
### Description: Refactor the LLMRouter to match the LLMPort contract exactly, ensuring all method signatures and behaviors are 1:1 and that provider selection is fully interchangeable with no call-site changes.
### Details:
Update router implementation to strictly enforce LLMPort method signatures and pass-through logic. Ensure that swapping providers via `LLMRouter(default_provider=...)` requires no changes at call sites and that all operations are routed correctly.

## 5. Develop Comprehensive Parity and Regression Test Suite [done]
### Dependencies: 29.1, 29.2, 29.3, 29.4
### Description: Create a parameterized test suite covering provider parity, token budgeting, provider-specific branches, router signature alignment, metadata normalization, stub-mode (no credentials), and backwards compatibility.
### Details:
Design tests to run all core operations across all providers, verifying consistent schemas, correct budgeting, feature branches (e.g., o-series, Claude thinking), router signature, and metadata normalization. Include stub-mode tests for environments without credentials. Document backwards compatibility and deprecation plan.
